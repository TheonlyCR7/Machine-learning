

## KNN算法

根据实际数据与现有数据的欧拉距离，找到与实际数据最相近的那些点，来确定实际数据的类别

欧拉距离



![image-20200606093739964](img/image-20200606093739964.png)



特点

*   没有模型的算法
*   可以将训练数据集就是模型本身

![image-20200606101839801](img/image-20200606101839801.png)



## 自己实现

通过机器学习库中 `sklearn.neighbors` 的 `KNeighborsClassifier` `knn`算法

```python
from sklearn.neighbors import KNeighborsClassifier
import numpy as np

# 训练数据    x代表坐标点   y代表类别
raw_data_X = [[3.393533211, 2.331273381],
              [3.110073483, 1.781539638],
              [1.343808831, 3.368360954],
              [3.582294042, 4.679179110],
              [2.280362439, 2.866990263],
              [7.423436942, 4.696522875],
              [5.745051997, 3.533989803],
              [9.172168622, 2.511101045],
              [7.792783481, 3.424088941],
              [7.939820817, 0.791637231]
             ]
raw_data_y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
# 实际数据  判断  x 数据点属于何种类别(x or y)
x = np.array([8.093607318, 3.365731514])

# 放到 numpy的数组中  x 为矩阵   y 为向量
X_train = np.array(raw_data_X)
y_train = np.array(raw_data_y)

# 与数据集距离最近的 n_neighbors=7 比较
kNN_classifier = KNeighborsClassifier(n_neighbors=7)
# 进行模型拟合
kNN_classifier.fit(X_train, y_train)
# 对样本进行处理
X_predict = x.reshape(1, -1)
# 进行样本预测
y_predict = kNN_classifier.predict(X_predict)
print(y_predict[0])
```



## KNN的性能

>   测试现有的数据集生成的模型的准确度，效率
>
>   改进算法

**train_test_split**

将数据集分成两部分：训练集，测试集

进行分类判断



## 超参数

KNN中决定样本数据与**K**个训练数据进行距离比较



```
knn_agls
├─ KNN.py				函数包装的te_demo.py
├─ KNN_in_scikit.py     调用机器学习库中的KNN实现样本分类
├─ KNN_test.py			将算法预测准确度的测试进行了封装
├─ my_own_KNN.py		自己实现的简易KNN算法
├─ own_KNN_test.py		使用自己的KNN算法
└─ te_demo.py			课程实例代码
```

